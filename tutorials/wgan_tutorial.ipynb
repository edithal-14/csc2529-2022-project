{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic model configuration\n",
    "clipping_param = 0.01\n",
    "\n",
    "# Training configuration\n",
    "device = torch.device(\"cuda:0\")\n",
    "batch_size = 64\n",
    "real_label = -1.0\n",
    "fake_label = 1.0\n",
    "n_epochs = 10\n",
    "n_critic = 5\n",
    "\n",
    "# Loss weight for gradient penalty\n",
    "use_gp = True\n",
    "lambda_gp = 10\n",
    "\n",
    "# Dataset configuration\n",
    "image_size = 28\n",
    "num_workers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init_critic(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, use_gp=False) -> None:\n",
    "        super(Critic, self).__init__()\n",
    "        # input_shape = 28\n",
    "        if use_gp:\n",
    "            self.main = nn.Sequential(\n",
    "                # input: 1 x 28 x 28\n",
    "                nn.Conv2d(1, 8, 4, stride=2, padding=3),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                # input: 8 x 16 x 16\n",
    "                nn.Conv2d(8, 16, 4, stride=2, padding=1),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                # input: 16 x 8 x 8\n",
    "                nn.Conv2d(16, 32, 4, stride=2, padding=1),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                # input: 32 x 4 x 4\n",
    "                nn.Conv2d(32, 1, 4, stride=1, padding=0),\n",
    "                # output: 1 x 1 x 1\n",
    "            )\n",
    "        else:\n",
    "            self.main = nn.Sequential(\n",
    "                # input: 1 x 28 x 28\n",
    "                nn.Conv2d(1, 8, 4, stride=2, padding=3),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                # input: 8 x 16 x 16\n",
    "                nn.Conv2d(8, 16, 4, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                # input: 16 x 8 x 8\n",
    "                nn.Conv2d(16, 32, 4, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                # input: 32 x 4 x 4\n",
    "                nn.Conv2d(32, 1, 4, stride=1, padding=0),\n",
    "                # output: 1 x 1 x 1\n",
    "            )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Conv2d(32, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_model = Critic(use_gp=use_gp).to(device)\n",
    "critic_model.apply(weight_init_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init_generator(m):\n",
    "    if isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input: 100 x 1 x 1\n",
    "            nn.ConvTranspose2d(100, 64, 4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # input: 64 x 4 x 4\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # input: 32 x 8 x 8\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # input: 16 x 16 x 16\n",
    "            nn.ConvTranspose2d(16, 1, 4, 2, 3),\n",
    "            nn.Tanh()\n",
    "            # output: 1 x 28 x 28\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2)\n",
       "    (9): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(3, 3))\n",
       "    (10): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_model = Generator().to(device)\n",
    "generator_model.apply(weight_init_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=\"mnist_root_dir\",\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5, 0.5)\n",
    "    ])\n",
    ")\n",
    "filter_digit = 8\n",
    "idx = dataset.targets == filter_digit\n",
    "dataset.targets = dataset.targets[idx]\n",
    "dataset.data = dataset.data[idx]\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_batch = next(iter(dataloader))\n",
    "plt.imshow(dummy_batch[0][23][0], cmap=\"gray_r\")\n",
    "plt.title(f\"Image for number: {dummy_batch[1][23]}\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_critic = optim.RMSprop(critic_model.parameters(), lr=5e-5)\n",
    "optimizer_generator = optim.RMSprop(generator_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training....\n",
      "Number of mini batch iterations per epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]MIOpen(HIP): Warning [SQLiteBase] Missing system database file: gfx1030_14.kdb Performance may degrade. Please follow instructions to install: https://github.com/ROCmSoftwarePlatform/MIOpen#installing-miopen-kernels-package\n",
      "92it [00:32,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, d_loss: -46.2468, g_loss: -87.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "92it [00:08, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, d_loss: -169.5318, g_loss: -432.3961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "92it [00:08, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, d_loss: -295.9826, g_loss: -1354.9689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "92it [00:08, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, d_loss: -72.1123, g_loss: -1846.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "92it [00:08, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, d_loss: -61.2996, g_loss: -1413.2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "92it [00:08, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, d_loss: -69.4700, g_loss: -1229.3959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "92it [00:08, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, d_loss: -63.9346, g_loss: -1033.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "92it [00:08, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, d_loss: -48.6964, g_loss: -906.6110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [00:08, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, d_loss: -57.3464, g_loss: -863.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "92it [00:08, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, d_loss: -79.5979, g_loss: -845.4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "print(\"Starting training....\")\n",
    "d_loss_hist = list()\n",
    "g_loss_hist = list()\n",
    "print(f\"Number of mini batch iterations per epoch: {len(dataloader)}\")\n",
    "for epoch in range(n_epochs):\n",
    "    for i, data in tqdm(enumerate(dataloader, 0)):\n",
    "        # Get batch of data\n",
    "        real_batch = data[0].to(device)\n",
    "        b_size = real_batch.shape[0]\n",
    "\n",
    "        d_loss_vals = list()\n",
    "        for _ in range(n_critic):\n",
    "            # Train critic weight for real images\n",
    "            critic_model.zero_grad()\n",
    "            d_loss_real = critic_model(real_batch)\n",
    "\n",
    "            # Update critic weight for fake images\n",
    "            noise = torch.randn(b_size, 100, 1, 1, device=device)\n",
    "            fake_batch = generator_model(noise)\n",
    "            d_loss_fake = critic_model(fake_batch)\n",
    "\n",
    "            d_loss = -torch.mean(d_loss_real - d_loss_fake)\n",
    "            if use_gp:\n",
    "                # Random weight term for interpolation\n",
    "                alpha = torch.rand(b_size, 1, 1, 1).to(device)\n",
    "                # Get random interpolations between real and fake\n",
    "                interpolates = torch.autograd.Variable(alpha * real_batch + (1 - alpha) * fake_batch, requires_grad=True).to(device)\n",
    "                d_interpolates = critic_model(interpolates)\n",
    "                fake = torch.autograd.Variable(torch.Tensor(d_interpolates.size()).fill_(1.0), requires_grad=False).to(device)\n",
    "                # Get gradient w.r.t interpolates\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=d_interpolates,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=fake,\n",
    "                    create_graph=True,\n",
    "                )[0]\n",
    "                gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "                d_loss += lambda_gp * gradient_penalty\n",
    "            d_loss_vals.append(d_loss.detach().cpu().numpy())\n",
    "            d_loss.backward()\n",
    "            optimizer_critic.step()\n",
    "\n",
    "            if use_gp:\n",
    "                # no op\n",
    "                ...\n",
    "            else:\n",
    "                # Clamp critic weights\n",
    "                for p in critic_model.parameters():\n",
    "                    p.data.clamp_(-clipping_param, clipping_param)\n",
    "\n",
    "        d_loss_hist.append(np.mean(d_loss_vals))\n",
    "\n",
    "        # Update generator weight\n",
    "        generator_model.zero_grad()\n",
    "        noise = torch.randn(b_size, 100, 1, 1, device=device)\n",
    "        fake_batch = generator_model(noise)\n",
    "        output = critic_model(fake_batch)\n",
    "        g_loss = -torch.mean(output)\n",
    "        g_loss_hist.append(g_loss.detach().cpu().numpy())\n",
    "        g_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "    # Summarize performance every epoch\n",
    "    if not epoch % 1:\n",
    "        tqdm.write(f\"epoch: {epoch}, d_loss: {d_loss_hist[-1]:.4f}, g_loss: {g_loss_hist[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(d_loss_hist, g_loss_hist):\n",
    "\t# plot history\n",
    "\tplt.plot(d_loss_hist, label='d_loss')\n",
    "\tplt.plot(g_loss_hist, label='g_loss')\n",
    "\tplt.legend()\n",
    "\tplt.savefig('loss_wgan_clamp.png')\n",
    "\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(d_loss_hist, g_loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_images():\n",
    "    # Generate 100 fake images\n",
    "    noise = torch.randn(100, 100, 1, 1, device=device)\n",
    "    output = generator_model(noise)\n",
    "    output = output.detach().cpu()\n",
    "    output = (output + 1) / 2\n",
    "    plt.clf()\n",
    "    for i in range(100):\n",
    "        plt.subplot(10, 10, i + 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(output[i, 0, :, :], cmap=\"gray_r\")\n",
    "    plt.savefig(\"fake_images_wgan_clamp.png\")\n",
    "    plt.close()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = generate_fake_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('vanilla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e79bffa39ae3b34dd6a67cfb7a86efb7a981f71c16a69aea29c61b44b39f0d36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
